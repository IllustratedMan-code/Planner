#import "@local/assignments:1.0.0": conf
#show: doc => conf(title: "Abstract 3", doc)
#set par(leading: 1em)
#import "@preview/wordometer:0.1.2": word-count, total-words
#show: word-count
#let total = [
  #set align(center)
  #box(stroke: black, inset: 5pt, radius: 5pt, [Word Count = #total-words])]

#let article_name = [_AI Tool Successfully Responds to Patient Questions in Electronic Health Record_]

#let paper_name = [_Large Language Model–Based Responses to Patients’ In-Basket Messages_]

In the article, #article_name, using AI tools to summarize patient data is addressed as a valid possibility to reduce health care professionals' workload. Important to note, the article is a summary of a paper published in JAMA, #paper_name. The main positive of using AI to summarize patient reports is, of course, the reduced workload for health care professionals. The main negative addressed in the article was the relatively high reading level outputted by the large language model generating the summary.

The article claims that "generative AI responses outperformed human providers in terms of understandability and tone by 9.5 percent". This refers to a metric from the original paper called "communication style" which includes understandability, tone, and verbosity. The article later claims that generative AI writes at a higher reading level than the equivalent health care professional. The original paper goes on to say that generative AI is more likely to be criticized for irrelevant information and verbosity, while health care providers are more likely to use jargon (difference is attributed to physicians). In essence, generative AI responses are likely to be on par, though often longer than health care professional responses.

In the article, William Small, MD claims that chatbots could reduce the workload of care providers by enabling efficient and empathetic responses to patients' concerns. The article does not address concerns that a generative AI response might be less likely to be verified by a health care professional than their own response. The article also does not consider that
generative AI may increase the workload of health care professionals rather than decrease it. The AAMC claims that there is a shortage of physicians in the U.S. @NewAAMCReport If physicians become more productive using generative AI tools, then it is logical that physicians will have to summarize more reports than previously to fit demand. This increase in workload would likely result in a decrease of AI supervision when generating patient messages.

Another potential negative of using generative AI for patient facing reports is patient perception of their physicians and the health care system as a whole. Perception of the health care system is low, according to the AAPA. @PatientExperiencePerspectives Part of that perception is the small amount of time a physician has to address a patient's concerns. If a patient believes that a physician has even less time to address their concerns, i.e. physicians need to use generative AI to handle their case load, will that patient believe their concerns are being heard?

It is claimed in the article that AI responses will be equal or superior to the responses generated by humans. This is a good thing, as patients will receive the responses they need without increasing the workload of physicians. However, AI "hype" must be balanced with the current state of the technology. Rushing to implement a product on the promise that "it will be better in the future", does not necessarily guarantee improvement in the _now_.

AI developments in healthcare are coming, and may improve patient outcomes. That being said, health care systems need to ensure that they do not damage the already tenuous relationship with patients.


#total

#bibliography("abstract3.bib")